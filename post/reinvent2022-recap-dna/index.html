<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width"><script type=application/javascript src=https://sanchitdilipjain.github.io/js/theme-mode.js></script><link rel=stylesheet href=https://sanchitdilipjain.github.io/css/frameworks.min.css><link rel=stylesheet href=https://sanchitdilipjain.github.io/css/github.min.css><link rel=stylesheet href=https://sanchitdilipjain.github.io/css/github-style.css><link rel=stylesheet href=https://sanchitdilipjain.github.io/css/light.css><link rel=stylesheet href=https://sanchitdilipjain.github.io/css/dark.css><link rel=stylesheet href=https://sanchitdilipjain.github.io/css/syntax.css><title>Recap of AWS re:Invent 2022 - Data & Analytics Highlights üìú - Sanchit's blog</title>
<link rel=icon type=image/x-icon href=https://sanchitdilipjain.github.io/images/github.png><meta name=theme-color content="#1e2327"><meta name=description content="Never become so much of an expert that you stop gaining expertise. View life as a continuous learning experience."><meta name=robots content="noodp"><link rel=canonical href=https://sanchitdilipjain.github.io/post/reinvent2022-recap-dna/><meta name=twitter:card content="summary"><meta name=twitter:title content="Sanchit's Blog"><meta name=twitter:description content="Recap of AWS re:Invent 2022 - Data & Analytics Highlights Overview
AWS re:Invent 2022 is in the bag! The 11th iteration of the annual cloud conference saw more than 50,000 partners and customers descend on Las Vegas in person, accompanied by more than 300,000 remote attendees. The event featured excellent keynote speakers, product announcements, training and certification opportunities, hands-on technical sessions, and more. I was thrilled to witness all of the fun, fully embracing AWS CEO Adam Selipsky&rsquo;s message that now is the perfect time to &ldquo;lean in harder&rdquo; to help clients accelerate their journey to the cloud. In this event, AWS made a couple of announcements focusing on AI/ML, Data, Analytics, Storage, App Integration, Infrastructure & Security. We will see the announcements from Data & Analytics that excite me in this blog post. Announcements from Database section
"><meta name=twitter:site content="https://sanchitdilipjain.github.io/"><meta name=twitter:creator content="Sanchit Jain"><meta name=twitter:image content="https://sanchitdilipjain.github.io//images/preview.png"><meta property="og:type" content="article"><meta property="og:title" content="Sanchit's Blog"><meta property="og:description" content="Never become so much of an expert that you stop gaining expertise. View life as a continuous learning experience."><meta property="og:url" content="https://sanchitdilipjain.github.io/"><meta property="og:site_name" content="Sanchit's Blog"><meta property="og:image" content="https://sanchitdilipjain.github.io//images/preview.png"><meta property="og:image:type" content="image/png"><meta name=thumbnail content="https://sanchitdilipjain.github.io//images/preview.png"><meta name=author content="Sanchit Jain"><meta property="article:published_time" content="2022-12-14 12:00:00 +0000 UTC"></head><body><style>.height-limitation{max-height:300px;overflow-y:scroll}.loader{border:4px solid #f3f3f3;border-bottom:4px solid var(--color-fg-muted);border-radius:50%;width:30px;height:30px;animation:spin 1s linear infinite;margin:0 auto}@keyframes spin{0%{transform:rotate(0)}100%{transform:rotate(360deg)}}</style><div style=position:relative><header class="Header js-details-container Details px-3 px-md-4 px-lg-5 flex-wrap flex-md-nowrap open Details--on"><div class="Header-item mobile-none" style=margin-top:-4px;margin-bottom:-4px><a class=Header-link href=https://sanchitdilipjain.github.io/><svg class="octicon" height="32" viewBox="0 0 16 16" width="32"><path fill-rule="evenodd" d="M8 0C3.58.0.0 3.58.0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38.0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95.0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12.0.0.67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15.0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48.0 1.07-.01 1.93-.01 2.2.0.21.15.46.55.38A8.013 8.013.0 0016 8c0-4.42-3.58-8-8-8z"/></svg></a></div><div class="Header-item d-md-none"><button class="Header-link btn-link js-details-target" type=button onclick='document.querySelector("#header-search").style.display=document.querySelector("#header-search").style.display=="none"?"block":"none"'><svg height="24" class="octicon octicon-three-bars" viewBox="0 0 16 16" width="24"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button></div><div style=display:none id=header-search class="Header-item Header-item--full flex-column flex-md-row width-full flex-order-2 flex-md-order-none mr-0 mr-md-3 mt-3 mt-md-0 Details-content--hidden-not-important d-md-flex"><div class="Header-search header-search flex-auto js-site-search position-relative flex-self-stretch flex-md-self-auto mb-3 mb-md-0 mr-0 mr-md-3 scoped-search site-scoped-search js-jump-to"><div class=position-relative><form target=_blank action=https://www.google.com/search accept-charset=UTF-8 method=get autocomplete=off><label class="Header-search-label form-control input-sm header-search-wrapper p-0 js-chromeless-input-container header-search-wrapper-jump-to position-relative d-flex flex-justify-between flex-items-center"><input type=text class="Header-search-input form-control input-sm header-search-input jump-to-field js-jump-to-field js-site-search-focus js-site-search-field is-clearable" name=q placeholder=Search autocomplete=off>
<input type=hidden name=q value=site:https://sanchitdilipjain.github.io/><div class="js-jump-to-suggestions-container jump-to-suggestions overflow-hidden position-absolute"><div id=search-progress class="d-none color-bg-primary no-underline p-2" role=progress aria-selected=false><div class=loader></div></div><ul id=jump-to-results role=listbox class="Box border-0 p-0 m-0 js-navigation-container jump-to-suggestions-results-container js-jump-to-suggestions-results-container js-active-navigation-container height-limitation"></ul></div></label></form></div></div></div><div class="Header-item Header-item--full flex-justify-center d-md-none position-relative"><a class=Header-link href=https://sanchitdilipjain.github.io/><svg class="octicon octicon-mark-github v-align-middle" height="32" viewBox="0 0 16 16" width="32"><path fill-rule="evenodd" d="M8 0C3.58.0.0 3.58.0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38.0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95.0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12.0.0.67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15.0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48.0 1.07-.01 1.93-.01 2.2.0.21.15.46.55.38A8.013 8.013.0 0016 8c0-4.42-3.58-8-8-8z"/></svg></a></div><div class=Header-item style=margin-right:0><a href=javascript:void(0) class="Header-link no-select" onclick=switchTheme()><svg style="fill:var(--color-profile-color-modes-toggle-moon)" class="no-select" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754c3.05612.0 5.53362-2.47748 5.53362-5.5336C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961 9.95801 1.07727 10.3495.771159 10.6474.99992c1.4679 1.12724 2.4141 2.90007 2.4141 4.89391.0 3.40575-2.7609 6.16667-6.16665 6.16667-2.94151.0-5.40199-2.0595-6.018122-4.81523C.794841 6.87902 1.23668 6.65289 1.55321 6.85451 2.41106 7.40095 3.4296 7.71754 4.52208 7.71754z"/></svg></a></div></header></div><div><main><div class="gisthead pagehead bg-gray-light pb-0 pt-3 mb-4"><div class=px-0><div class="mb-3 d-flex px-3 px-md-3 px-lg-5"><div class="flex-auto min-width-0 width-fit mr-3"><div class=d-flex><div class="d-none d-md-block"><a class="avatar mr-2 flex-shrink-0" href=https://sanchitdilipjain.github.io/><img class=avatar-user src=https://sanchitdilipjain.github.io/images/avatar.png width=32 height=32></a></div><div class="d-flex flex-column"><h1 class="break-word f3 text-normal mb-md-0 mb-1"><span class=author><a href=https://sanchitdilipjain.github.io/>Sanchit Dilip Jain</a></span><span class=path-divider>/</span><strong class="css-truncate-target mr-1" style=max-width:410px><a href=https://sanchitdilipjain.github.io/post/reinvent2022-recap-dna/>Recap of AWS re:Invent 2022 - Data & Analytics Highlights üìú</a></strong></h1><div class="note m-0">Created <relative-time datetime="Wed, 14 Dec 2022 12:00:00 +0000" class=no-wrap>Wed, 14 Dec 2022 12:00:00 +0000</relative-time>
<span class=file-info-divider></span>
Modified <relative-time datetime="Thu, 05 Dec 2024 16:56:15 +0000" class=no-wrap>Thu, 05 Dec 2024 16:56:15 +0000</relative-time></div></div></div></div></div></div></div><div class="container-lg px-3 new-discussion-timeline"><div class="repository-content gist-content"><div><div class="js-gist-file-update-container js-task-list-container file-box"><div id=file-pytest class="file my-2"><div id=post-header class="file-header d-flex flex-md-items-center flex-items-start sticky-header" style=z-index:2><div class="file-info d-flex flex-md-items-center flex-items-start flex-order-1 flex-auto"><div class="text-mono f6 flex-auto pr-3 flex-order-2 flex-md-order-1 mt-2 mt-md-0"><summary id=toc-toggle onclick=clickToc() class="btn btn-octicon m-0 mr-2 p-2"><svg aria-hidden="true" viewBox="0 0 16 16" height="16" width="16" class="octicon octicon-list-unordered"><path fill-rule="evenodd" d="M2 4a1 1 0 100-2 1 1 0 000 2zm3.75-1.5a.75.75.0 000 1.5h8.5a.75.75.0 000-1.5h-8.5zm0 5a.75.75.0 000 1.5h8.5a.75.75.0 000-1.5h-8.5zm0 5a.75.75.0 000 1.5h8.5a.75.75.0 000-1.5h-8.5zM3 8A1 1 0 111 8a1 1 0 012 0zm-1 6a1 1 0 100-2 1 1 0 000 2z"/></svg></summary><details-menu class=SelectMenu id=toc-details style="display: none;"><div class="SelectMenu-modal rounded-3 mt-1" style=max-height:340px><div class="SelectMenu-list SelectMenu-list--borderless p-2" style=overscroll-behavior:contain id=toc-list></div></div></details-menu>3072 Words
<span class=file-info-divider></span>
14 min</div></div></div><div class="Box-body px-5 pb-5" style=z-index:1><article class="markdown-body entry-content container-lg"><h2 id=recap-of-aws-reinvent-2022---data--analytics-highlights>Recap of AWS re:Invent 2022 - Data & Analytics Highlights</h2><p><strong>Overview</strong></p><ul><li>AWS re:Invent 2022 is in the bag! The 11th iteration of the annual cloud conference saw more than 50,000 partners and customers descend on Las Vegas in person, accompanied by more than 300,000 remote attendees.</li><li>The event featured excellent keynote speakers, product announcements, training and certification opportunities, hands-on technical sessions, and more. I was thrilled to witness all of the fun, fully embracing AWS CEO Adam Selipsky&rsquo;s message that now is the perfect time to &ldquo;lean in harder&rdquo; to help clients accelerate their journey to the cloud.</li><li>In this event, AWS made a couple of announcements focusing on AI/ML, Data, Analytics, Storage, App Integration, Infrastructure & Security. We will see the announcements from Data & Analytics that excite me in this blog post.</li></ul><p><strong>Announcements from Database section</strong></p><ol><li><p><a href=https://aws.amazon.com/blogs/aws/new-a-fully-managed-schema-conversion-in-aws-database-migration-service/>Schema Conversion feature in AWS DMS</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image1.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>DMS Schema Conversion is a fully managed feature of AWS DMS that automatically assesses and converts the database schema to a format compatible with the target database service in AWS, enabling you to modernize your database and analytics workloads</li><li>With the DMS Schema Conversion feature built into DMS, customers can avoid the hassle of implementing piecemeal solutions, especially for heterogeneous migrations.</li><li>This feature allows you to convert the schema, views, stored procedures, and functions from a source database into the schema for the target database service.</li></ul></li><li><p><strong>Considerations and Limitations:</strong></p><ul><li>You can&rsquo;t save a migration project and use it in an offline mode.</li><li>Migration rules in DMS Schema Conversion don&rsquo;t support changing column collation. Also, you can&rsquo;t use migration rules to move objects to a new schema.</li><li>You can&rsquo;t apply filters to your source and target database trees to display only those database objects that meet the filter clause.</li><li>DMS Schema Conversion extension pack doesn&rsquo;t include AWS Lambda functions that emulate email sending, job scheduling, and other features in your converted code.</li></ul></li></ul></li><li><p><a href=https://aws.amazon.com/blogs/aws/new-fully-managed-blue-green-deployments-in-amazon-aurora-and-amazon-rds/>Amazon RDS Blue/Green Deployments for safer, simpler, and faster updates</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image4.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>Amazon RDS Blue/Green Deployments helps us with safer, simpler, and faster updates to your Amazon Aurora and Amazon RDS databases.</li><li>Blue/Green Deployments create a fully managed staging environment that allows you to deploy and test production changes, keeping your current production database safe.</li><li>Amazon RDS Blue/Green Deployments can be leveraged for deploying changes to production, such as major and minor version database engine upgrades, schema updates, maintenance updates, database parameter setting changes, and scaling instances.</li><li>Blue/Green Deployments use built-in switchover guardrails that will time-out promotion of the staging environment if it exceeds your maximum tolerable downtime, detects replication errors, or identifies instance health check errors.</li></ul></li><li><p><strong>UseCases:</strong></p><ul><li>Major/Minor version upgrades</li><li>Schema changes</li><li>Instance scaling</li><li>Engine parameter changes</li><li>Maintenance updates</li></ul></li></ul></li><li><p><a href=https://aws.amazon.com/about-aws/whats-new/2022/11/amazon-aurora-zero-etl-integration-redshift/>Amazon Aurora zero-ETL integration with Amazon Redshift</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image12.png alt></p><ul><li><strong>Overview:</strong><ul><li>Amazon Aurora now supports zero-ETL integration with Amazon Redshift to enable near real-time analytics and machine learning (ML) using Amazon Redshift on petabytes of transactional data from Aurora.</li><li>Within seconds of transactional data being written into Aurora, the data is available in Amazon Redshift, so you don‚Äôt have to build and maintain complex data pipelines to perform extract, transform, and load (ETL) operations.</li><li>This zero-ETL integration allows you to analyze data from multiple Aurora database clusters in the same new or existing Amazon Redshift instance to derive holistic insights across many applications or partitions.</li><li>Amazon Aurora zero-ETL integration with Amazon Redshift is now available in a limited preview for Amazon Aurora MySQL 3 with MySQL 8.0 compatibility in the US East (N. Virginia) Region</li></ul></li></ul></li><li><p><a href=https://aws.amazon.com/opensearch-service/features/serverless/>Amazon OpenSearch Serverless (Preview)</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image2.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>Amazon OpenSearch Serverless simplifies the process of running petabyte-scale search and analytics workloads without configuring, managing or scaling OpenSearch clusters.</li><li>OpenSearch Serverless automatically provisions and scales the underlying resources to deliver fast data ingestion and query responses for even the most demanding and unpredictable workloads.</li><li>With OpenSearch Serverless, you pay only for the resources consumed</li><li>OpenSearch Serverless decouples compute and storage and separates the indexing (ingest) components from the search (query) components, with Amazon Simple Storage Service (Amazon S3) as the primary data storage for indexes</li><li>With this decoupled architecture, OpenSearch Serverless can scale search and indexing functions independently of each other and independently of the indexed data in Amazon S3</li></ul></li><li><p><strong>Benefits:</strong></p><ul><li>OpenSearch Serverless removes much of the complexity of managing OpenSearch clusters and capacity.</li><li>When you use OpenSearch Serverless, you only pay for the resources you consume. This removes the need for upfront provisioning and overprovisioning for peak workloads.</li><li>OpenSearch Serverless supports production workloads with redundancy to protect against Availability Zone outages and infrastructure failures.</li><li>OpenSearch Serverless automatically scales resources to maintain consistently fast data ingestion rates and query response times.</li></ul></li></ul></li><li><p><a href=https://aws.amazon.com/blogs/aws/announcing-amazon-documentdb-elastic-clusters/>Amazon DocumentDB (with MongoDB compatibility) Elastic Clusters</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image6.png alt></p><ul><li><strong>Overview:</strong><ul><li>Amazon DocumentDB Elastic Clusters, a new type of Amazon DocumentDB cluster that lets you elastically scale your document database to handle millions of reads and writes per second with petabytes of storage.</li><li>With Amazon DocumentDB Elastic Clusters, we can leverage the MongoDB Sharding API to create scalable collections that can be petabytes in size.</li><li>Scaling Amazon DocumentDB Elastic Clusters is as simple as changing the number of cluster shards in the console, and the Amazon DocumentDB service handles the rest. It can be as fast as minutes compared to hours when done manually.</li><li>Amazon DocumentDB Elastic Clusters provide many of the same management capabilities as Amazon DocumentDB instance-based clusters, including Multi-AZ support, AWS CloudWatch integration, automated patching, and snapshot back-ups.</li></ul></li></ul></li></ol><p><strong>Announcements from Analytics section</strong></p><ol><li><p><a href=https://aws.amazon.com/datazone/>Amazon Datazone</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image7.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>Amazon DataZone is a data management service that you can use to publish data and make it available to the business data catalog through your personalized web application.</li><li>You can access your data more securely regardless of where it is stored‚Äîon AWS, on-premises, or in SaaS applications like Salesforce.</li><li>Amazon DataZone simplifies your experience across AWS services like Amazon Redshift, Amazon Athena, AWS Glue, AWS Lake Formation, and Amazon QuickSight.</li></ul></li><li><p><strong>Benefits:</strong></p><ul><li>Get a 360-degree view of all your trusted business data regardless of where it is stored.</li><li>Increase productivity by inviting team members to collaborate and access data project assets and analytics tools.</li><li>Analyze data with a personalized view of your projects without signing in to the AWS Management Console.</li><li>Access your data following your organization‚Äôs security and compliance regulations.</li></ul></li><li><p><strong>UseCases:</strong></p><ul><li>Use business terms to search, share, and access cataloged data stored on AWS, on-premises, or with third-party providers.</li><li>Increase your efficiency by collaborating seamlessly across teams and accessing data and analytics tools in a self-service fashion</li><li>Manage and govern data access following your organization‚Äôs security regulations from a single place.</li><li>Get a personalized view to discover, prepare, transform, analyze, and visualize data using a web-based application.</li></ul></li></ul></li><li><p><a href=https://docs.aws.amazon.com/quicksight/latest/APIReference/Welcome.html>Expanded API capabilities for Amazon QuickSight</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image8.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>Amazon QuickSight now offers expanded API capabilities, allowing programmatic access to the underlying structure of QuickSight dashboards and analyses with the AWS Software Development Kit.</li><li>With the new APIs, you can create programmatic migration accelerators that expedite business intelligence (BI) migrations to the cloud.</li></ul></li><li><p><strong>Benefits:</strong></p><ul><li>The new and expanded APIs let customers and developers treat QuickSight assets like software code and integrate with DevOps processes, such as code reviews, audits, and promotion across development and production environments</li></ul></li><li><p><strong>APIs:</strong></p><ul><li>Amazon QuickSight API operations provide:<ul><li>User and group management</li><li>Data management (data sources, datasets, templates, and SPICE ingestion)</li><li>Dashboard and analysis management</li><li>Template management</li><li>Permissions management</li><li>Customization management</li></ul></li></ul></li></ul></li><li><p><a href=https://docs.aws.amazon.com/glue/latest/dg/author-job-ray.html>AWS Glue for Ray (Preview)</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image9.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>AWS Glue for Ray is a new engine option on AWS Glue. Data engineers can use AWS Glue for Ray to process large datasets with Python and popular Python libraries.</li><li>AWS Glue for Ray combines that serverless option for data integration with Ray (ray.io), a popular new open-source compute framework that helps you scale Python workloads</li></ul></li><li><p><strong>Benefits:</strong></p><ul><li>Ray automates scaling Python code by distributing the processing across a cluster of machines that it reconfigures in real time based on the load.</li><li>With Ray jobs, AWS has built auto-scaling natively into the AWS Glue job model, so we can fully take advantage of this feature.</li><li>Ray jobs run on AWS Graviton, leading to higher overall price performance</li></ul></li><li><p><strong>Integration:</strong></p><ul><li><p>Through the AWS SDK for pandas, Ray jobs currently support the following connections</p><table><thead><tr><th>Connection</th><th>Read</th><th>Write</th></tr></thead><tbody><tr><td>Amazon S3</td><td>Supported</td><td>Supported</td></tr><tr><td>Athena</td><td>Supported</td><td>N/A</td></tr><tr><td>LakeFormation goverened tables</td><td>Supported</td><td>Supported</td></tr><tr><td>Timestream</td><td>Supported</td><td>Supported</td></tr></tbody></table></li><li><p>Through the AWS SDK for pandas, Ray jobs support the following format types:</p><ul><li>Parquet</li><li>CSV</li><li>JSON</li><li>XSLX</li></ul></li></ul></li></ul></li><li><p><a href=https://aws.amazon.com/blogs/aws/new-create-and-share-operational-reports-at-scale-with-amazon-quicksight-paginated-reports/>Amazon QuickSight Paginated Reports</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image10.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>Amazon QuickSight now supports Paginated Reports, which allows capturing detailed operational data in custom formats to facilitate critical and day-to-day business processes.</li><li>Paginated Reports allows you to create, schedule, and share highly formatted multipage reports and schedule data exports at scale.</li></ul></li><li><p><strong>Benefits:</strong></p><ul><li>Get business-critical information to users on how and when they need it with critical operational reports and dashboards in the same solution.</li><li>With the QuickSight serverless architecture, share your reports at scale without any hardware management. Reduce costs with the QuickSight consumption-based pricing model.</li><li>Start building critical operational reports without special coding skills or learning to use a separate tool.</li></ul></li><li><p><strong>Availability:</strong></p><ul><li>Amazon QuickSight Paginated Reports is available as an add-on to the existing Amazon QuickSight Enterprise or Enterprise enabled with Q in all supported AWS Regions.</li></ul></li></ul></li><li><p><a href=https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-datalake-native-frameworks.html>AWS Glue for Apache Spark Native support for Data Lake Frameworks</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image18.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>AWS Glue for Apache Spark now supports three open-source data lake storage frameworks: Apache Hudi, Apache Iceberg, and Linux Foundation Delta Lake.</li><li>These frameworks allow you to read and write data in Amazon Simple Storage Service (Amazon S3) in a transactionally consistent manner.</li><li>They enable capabilities including time travel queries, ACID (Atomicity, Consistency, Isolation, Durability) transactions, streaming ingestion, change data capture (CDC), upserts, and deletes.</li></ul></li><li><p><strong>Benefits:</strong></p><ul><li>There&rsquo;s no need to install a separate connector or complete extra configuration steps to use these frameworks in AWS Glue ETL jobs.</li></ul></li></ul></li><li><p><a href=https://aws.amazon.com/blogs/aws/new-aws-glue-4-0-new-and-updated-engines-more-data-formats-and-more/>Introducing AWS Glue 4.0</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image11.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>AWS Glue version 4.0, a new version of AWS Glue that accelerates data integration workloads in AWS.</li><li>AWS Glue 4.0 upgrades the Spark engines to Apache Spark 3.3.0 and Python 3.10 to develop, run, and scale their data integration workloads and get insights faster.</li><li>AWS Glue 4.0 supports built-in Pandas APIs and Apache Hudi, Apache Iceberg, and Delta Lake formats, giving you more options for analyzing and storing your data.</li><li>AWS Glue 4.0 also adds native support for the new Cloud Shuffle Storage Plugin for Apache Spark, which helps customers scale their disk usage during runtime.</li></ul></li><li><p><strong>Benefits:</strong></p><ul><li>AWS Glue version 4.0 enables Adaptive Query Execution, which dynamically optimizes your queries as it runs.</li><li>It upgrades connectors for native AWS Glue database sources such as RDS, MySQL, and SQLServer, simplifying connections to familiar database sources.</li></ul></li><li><p><strong>Considerations and Limitations:</strong></p><ul><li>AWS Glue streaming jobs and interactive sessions have yet to be available in AWS Glue 4.0.</li><li>AWS Glue machine learning and personally identifiable information (PII) transforms have yet to be available in AWS Glue 4.0.</li></ul></li></ul></li><li><p><a href=https://docs.aws.amazon.com/redshift/latest/dg/t_ddm.html>Amazon Redshift for Dynamic Data Masking (Preview)</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image17.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>With Dynamic data masking, you control access to your data through simple SQL-based masking policies that determine how Redshift returns sensitive data to the user at query time.</li><li>Dynamic data masking policies hide, obfuscate or pseudonymize data that matches a given format.</li><li>We can also mask policies to only apply them to certain users or user-defined roles that you can create with Role-based access control (RBAC)</li></ul></li><li><p><strong>Benefits:</strong></p><ul><li>We can manipulate how Amazon Redshift shows sensitive data to the user at query time without transforming it in the database.</li></ul></li></ul></li><li><p><a href=https://aws.amazon.com/blogs/aws/new-for-amazon-redshift-general-availability-of-streaming-ingestion-for-kinesis-data-streams-and-managed-streaming-for-apache-kafka/>Amazon Redshift real-time streaming for Amazon KDS and Amazon MSK</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image14.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>Amazon Redshift Streaming Ingestion is a new capability via which we can natively ingest hundreds of megabytes of data per second from Amazon Kinesis Data Streams and Amazon MSK into an Amazon Redshift materialized view and query it in seconds.</li><li>Amazon Redshift streaming ingestion simplifies data pipelines by letting you directly create materialized views on top of streams. The materialized views can also include SQL transforms as part of your ELT (Extract Load Transform) pipeline.</li><li>This approach allows you to perform downstream processing and transformations of streaming data using existing Amazon Redshift tools and SQL that you are familiar with at no additional cost.</li></ul></li><li><p><strong>Considerations and Limitations:</strong></p><ul><li>Kafka topic length limit - the name shouldn‚Äôt be longer than 128 characters (not including quotation marks).</li><li>The materialized view must be incrementally maintainable. And JOINs are not currently supported on materialized views created on a Kinesis stream or an Amazon MSK topic.</li><li>Amazon Redshift streaming ingestion doesn&rsquo;t support parsing records that the Kinesis Producer Library has aggregated. The aggregated records are ingested but are stored as binary protocol buffer data.</li><li>The maximum size of any record field Amazon Redshift can ingest from Kinesis or Amazon MSK is slightly less than 1MB</li><li>In each case where a record can&rsquo;t be ingested to Amazon Redshift because the data size exceeds the maximum size, that record is skipped.</li></ul></li></ul></li><li><p><a href=https://aws.amazon.com/blogs/aws/new-amazon-redshift-integration-with-apache-spark/>Amazon Redshift integration for Apache Spark</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image16.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>Amazon Redshift integration for Apache Spark helps developers seamlessly build and run Apache Spark applications on Amazon Redshift data.</li><li>Amazon Redshift integration for Apache Spark builds on an open-source connector project and enhances it for performance and security, helping customers gain up to 10x faster application performance.</li><li>Amazon, Redshift Integration for Apache Spark, also uses AWS Identity Access and Management (IAM)-based credentials to enhance security.</li></ul></li><li><p><strong>UseCases:</strong></p><ul><li>Expand the breadth of data sources that you can use in your rich analytics and machine learning (ML) applications running in Amazon EMR, AWS Glue, or SageMaker by reading from and writing data to your data warehouse</li><li>Use several pushdown capabilities such as sort, aggregate, limit, join, and scalar functions to move only relevant data from the Amazon Redshift data warehouse.</li></ul></li><li><p><strong>Availability:</strong></p><ul><li>The Amazon Redshift integration for Apache Spark is now available in all Regions that support Amazon EMR 6.9, AWS Glue 4.0, and Amazon Redshift. We can use the feature directly from EMR 6.9 and Glue Studio 4.0 with the new Spark 3.3.0 version.</li></ul></li></ul></li><li><p><a href=https://aws.amazon.com/clean-rooms/>AWS Clean Rooms (preview)</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image3.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>AWS Clean Rooms helps multiple parties easily and securely match, analyze, and collaborate on their combined data sets without needing to maintain a copy of their data outside of their AWS environment or load it into another platform</li><li>With AWS Clean Rooms, customers can create a secure data clean room in minutes and collaborate with any other company on the AWS Cloud to generate unique insights about advertising campaigns, investment decisions, and research and development.</li><li>AWS Clean Rooms provides a broad set of configurable data access controls<ul><li>including query controls, query output restrictions, and query logging</li><li>that allow companies to customize restrictions on the queries run by each clean room participant</li></ul></li></ul></li><li><p><strong>Benefits:</strong></p><ul><li>Create your clean room, add participants, and start collaborating in a few clicks.</li><li>Collaborate with hundreds of thousands of companies on AWS without sharing or revealing underlying data.</li><li>Protect underlying data with a broad set of privacy-enhancing controls for clean rooms.
Use flexible, easy-to-configure analysis rules to tailor queries to your business needs.</li></ul></li></ul></li><li><p><a href=https://docs.aws.amazon.com/redshift/latest/dg/loading-data-copy-job.html>Amazon Redshift now supports auto-copy from Amazon S3(preview)</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image13.png alt></p><ul><li><strong>Overview:</strong><ul><li>Amazon Redshift launches the preview of auto-copy support to simplify data loading from Amazon S3 into Amazon Redshift.</li><li>We can now set up continuous file ingestion rules to track your Amazon S3 paths and automatically load new files without needing additional tools or custom solutions.</li><li>We can now store a COPY statement into a Copy Job, automatically loading the new files detected in the Amazon S3 path. Copy Jobs track previously loaded files and exclude them from the ingestion process.</li><li>Copy Jobs can also be manually executed to reuse copy statements and prevent data duplication when automated loading is unnecessary.</li><li>We can query system views to see the COPY JOB status and progress. Views are provided as follows:<ul><li>SYS_COPY_JOB (preview) ‚Äì contains a row for each currently defined COPY JOB.</li><li>STL_LOAD_ERRORS ‚Äì contains errors from COPY commands.</li><li>STL_LOAD_COMMITS ‚Äì contains information used to troubleshoot a COPY command data load.</li><li>SYS_LOAD_HISTORY ‚Äì contains details of COPY commands.</li><li>SYS_LOAD_ERROR_DETAIL ‚Äì contains details of COPY command errors.</li></ul></li></ul></li></ul></li><li><p><a href=https://aws.amazon.com/blogs/big-data/centrally-manage-access-and-permissions-for-amazon-redshift-data-sharing-with-aws-lake-formation/>Amazon Redshift data sharing centralized access control with AWS Lake formation (Preview)</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image15.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>Amazon Redshift now supports simplified governance of Amazon Redshift data sharing by enabling you to use AWS Lake Formation to manage permissions on shared data across your organization centrally.</li><li>Enabling Lake Formation managed data sharing will help to manage granular entitlements such as table-level, column-level, or row-level access to tables being shared in Redshift data sharing and Redshift external tables.</li></ul></li><li><p><strong>Considerations and Limitations:</strong></p><ul><li>Amazon Redshift currently supports data sharing via Lake Formation when sharing within the same account or across accounts. Cross-Region sharing is currently not supported.</li><li>Row-level filters are unsupported for views.</li><li>Cell-level filters are unsupported.</li><li>You can&rsquo;t create materialized views based on a table if the table has Lake Formation filters configured.</li></ul></li></ul></li><li><p><a href=https://aws.amazon.com/blogs/aws/join-the-preview-aws-glue-data-quality/>AWS Glue announces AWS Glue Data Quality (Preview)</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image19.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>AWS Glue announces the preview of AWS Glue Data Quality, a new capability that automatically measures and monitors data lake and data pipeline quality</li><li>AWS Glue Data Quality uses open-source Deequ to evaluate rules. AWS uses Deequ to measure and monitor the data quality of petabyte-scale data lakes</li><li>AWS Glue Data Quality automatically analyzes your data to gather data statistics. It then recommends data quality rules to get started.</li><li>Data quality rules and actions can also be configured on AWS Glue extract, transform, and load (ETL) jobs on data pipelines. These guidelines can prevent ‚Äúbad‚Äù data from entering data lakes and data warehouses.</li></ul></li><li><p><strong>Benefits:</strong></p><ul><li>Detect data quality issues - you can check for issues by creating rules that check the characteristics of your datasets.</li><li>It&rsquo;s easy to get started - you can begin with pre-built rules and actions.</li><li>Tight integration - you use data quality nodes in AWS Glue Studio as data quality runs on top of the AWS Glue Data Catalog.</li></ul></li></ul></li><li><p><a href=https://aws.amazon.com/blogs/aws/new-amazon-athena-for-apache-spark/>Amazon Athena now supports Apache Spark</a></p><p><img src=https://sanchitdilipjain.github.io/images/reinvent2022-recap/image5.png alt></p><ul><li><p><strong>Overview:</strong></p><ul><li>Amazon Athena now supports Apache Spark, a popular open-source distributed processing system optimized for fast analytics workloads against data of any size.</li><li>With Amazon Athena for Apache Spark, we get the streamlined, interactive, serverless experience of Athena with Spark and SQL.</li><li>With Athena, interactive Spark applications start in under a second and run faster with our optimized Spark runtime, so you spend more time on insights, not waiting for results.</li><li>Apache Spark on Amazon Athena is serverless and provides automatic, on-demand scaling that delivers instant-on compute to meet changing data volumes and processing requirements.</li></ul></li><li><p><strong>Benefits:</strong></p><ul><li>Accelerate time to insights</li><li>Harness Spark for complex, powerful analytics</li><li>Build applications without managing resources</li><li>Work with your data where it lives</li></ul></li><li><p><strong>Considerations and Limitations:</strong></p><ul><li>AWS Lake Formation is not supported.</li></ul></li></ul></li></ol></article></div></div></div></div></div><div class=pagination-nav><div class="pagination-button next-post"><div>¬´&nbsp;</div><a class="pagination-link link-reverse" href=https://sanchitdilipjain.github.io/post/reinvent2022-recap-devops/>Recap of AWS re:Invent 2022 - App Integration,...</a></div><div class="pagination-button previous-post"><a class="pagination-link link-reverse" href=https://sanchitdilipjain.github.io/webinar/aws-re-invent-2022---pex308/>AWS re:Invent 2022 - Reinvent your business with...&nbsp;</a><div>¬ª</div></div></div></div></main></div><script type=application/javascript src=https://sanchitdilipjain.github.io/js/toc.js></script><link rel=stylesheet href=https://sanchitdilipjain.github.io/css/toc.css><div class="footer container-xl width-full p-responsive"><div class="position-relative d-flex flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between flex-sm-items-center pt-6 pb-2 mt-6 f6 text-gray border-top border-gray-light"><a aria-label=Homepage title=GitHub class="footer-octicon d-none d-lg-block mr-lg-4" href=https://sanchitdilipjain.github.io/><svg height="24" class="octicon octicon-mark-github" viewBox="0 0 16 16" width="24"><path fill-rule="evenodd" d="M8 0C3.58.0.0 3.58.0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38.0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95.0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12.0.0.67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15.0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48.0 1.07-.01 1.93-.01 2.2.0.21.15.46.55.38A8.013 8.013.0 0016 8c0-4.42-3.58-8-8-8z"/></svg></a><ul class="list-style-none d-flex flex-wrap col-12 flex-justify-center flex-lg-justify-between mb-2 mb-lg-0"><li class="mr-3 mr-lg-0"></li></ul></div><div class="d-flex flex-justify-center pb-6"><span class="f6 text-gray-light"></span></div></div></body><script type=application/javascript src=https://sanchitdilipjain.github.io/js/github-style.js></script><script src=https://sanchitdilipjain.github.io/js/mark.es6.min.js></script></html>