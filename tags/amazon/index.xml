<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Amazon on Sanchit's blog</title><link>https://sanchitdilipjain.github.io/tags/amazon/</link><description>Recent content in Amazon on Sanchit's blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 05 Dec 2024 11:11:14 +0000</lastBuildDate><atom:link href="https://sanchitdilipjain.github.io/tags/amazon/index.xml" rel="self" type="application/rss+xml"/><item><title>Securing Your Code With Amazon Q Developer 🔍</title><link>https://sanchitdilipjain.github.io/post/secure-coding-with-amazon-q/</link><pubDate>Sun, 14 Jul 2024 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/secure-coding-with-amazon-q/</guid><description>&lt;h2 id="securing-your-code-with-amazon-q-developer">Securing Your Code With Amazon Q Developer&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>What is Amazon Q Developer?&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>Amazon Q Developer is a generative artificial intelligence (AI) powered conversational assistant that can help us understand, build, extend, and operate AWS applications.&lt;/li>
&lt;li>We can ask questions about AWS architecture, our AWS resources, best practices, documentation, support, and more. Amazon Q is constantly updating its capabilities so our questions get the most contextually relevant and actionable answers.&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>How Amazon Q Developer help us with secure coding?&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>Amazon Q Developer offers powerful capabilities to enhance code security throughout the development lifecycle. By leveraging its advanced scanning and analysis features, developers can identify and address potential vulnerabilities early in the process.&lt;/p></description></item><item><title>Integrate Jfrog Artifactory with AWS Managed workflow for Apache Airflow 🔍</title><link>https://sanchitdilipjain.github.io/post/integrate-jfrog-with-amwa/</link><pubDate>Wed, 19 Jun 2024 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/integrate-jfrog-with-amwa/</guid><description>&lt;h2 id="integrate-jfrog-artifactory-with-aws-managed-workflow-for-apache-airflow">Integrate Jfrog Artifactory with AWS Managed workflow for Apache Airflow&lt;/h2>
&lt;p>&lt;strong>Overview&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>When managing data pipelines and workflows in AWS Managed Apache Airflow, it&amp;rsquo;s often necessary to integrate with various external services for tasks such as downloading binaries, libraries, or other dependencies.&lt;/li>
&lt;li>JFrog Artifactory is a popular binary repository manager that allows you to securely store and manage artifacts. Integrating JFrog with AWS Managed Apache Airflow enables seamless and secure downloading of these artifacts, ensuring that your workflows can reliably access the necessary resources.&lt;/li>
&lt;li>This integration is crucial for maintaining consistency and security across your deployment pipelines, allowing you to automate complex workflows without manual intervention.&lt;/li>
&lt;li>By using AWS Secrets Manager and a startup script, we can securely manage the credentials required for this integration, ensuring that sensitive information is handled safely.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Demo&lt;/strong>&lt;/p></description></item><item><title>Integrate AWS Secret Manager with AWS Managed workflow for Apache Airflow 🔍</title><link>https://sanchitdilipjain.github.io/post/integrate-secret-with-amwa/</link><pubDate>Tue, 18 Jun 2024 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/integrate-secret-with-amwa/</guid><description>&lt;h2 id="integrate-aws-secret-manager-with-aws-managed-workflow-for-apache-airflow">Integrate AWS Secret Manager with AWS Managed workflow for Apache Airflow&lt;/h2>
&lt;p>&lt;strong>Overview&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>What is AWS Managed Apache Airflow?&lt;/p>
&lt;ul>
&lt;li>AWS Managed Apache Airflow (MWAA) is a managed service that makes it easier to run and manage workflows built with Apache Airflow on AWS. Apache Airflow is an open-source tool used to programmatically author, schedule, and monitor workflows.&lt;/li>
&lt;li>With MWAA, AWS takes care of the operational aspects such as scaling, patching, and availability, allowing you to focus on building and managing your workflows.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>What is AWS Secrets Manager?&lt;/p></description></item><item><title>Amazon Bedrock Agent - Overview 🔍</title><link>https://sanchitdilipjain.github.io/post/amazon-bedrock-agent/</link><pubDate>Fri, 17 May 2024 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-bedrock-agent/</guid><description>&lt;h2 id="amazon-bedrock-agent---overview">Amazon Bedrock Agent - Overview&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>What is Amazon Bedrock?&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aws.amazon.com/bedrock/">Amazon Bedrock&lt;/a> is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like Stability AI, Anthropic, and Meta via a single API. It also provides the broad capabilities needed to build Generative AI applications with security, privacy, and responsible AI.&lt;/li>
&lt;li>Since Amazon Bedrock is serverless, you don&amp;rsquo;t have to manage any infrastructure, and you can
securely integrate and deploy Generative AI capabilities into your applications using the AWS services you already know.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>What Agents for Amazon Bedrock?&lt;/p></description></item><item><title>Amazon Bedrock Knowledge Bases - Overview 🔍</title><link>https://sanchitdilipjain.github.io/post/amazon-bedrock-kb/</link><pubDate>Thu, 16 May 2024 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-bedrock-kb/</guid><description>&lt;h2 id="amazon-bedrock-knowledge-bases---overview">Amazon Bedrock Knowledge Bases - Overview&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>What is Amazon Bedrock?&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>&lt;a href="https://aws.amazon.com/bedrock/">Amazon Bedrock&lt;/a> is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like Stability AI, Anthropic, and Meta via a single API. It also provides the broad capabilities needed to build Generative AI applications with security, privacy, and responsible AI.&lt;/li>
&lt;li>Since Amazon Bedrock is serverless, you don&amp;rsquo;t have to manage any infrastructure, and you can
securely integrate and deploy Generative AI capabilities into your applications using the AWS services you already know.&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>What are embeddings in RAG workflow?&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>An embedding is a way of representing documents as vectors in a high-dimensional space. These vectors capture the essence of the document&amp;rsquo;s content in a form that machines can process. By converting text into embeddings, we enable the computer to &amp;lsquo;understand&amp;rsquo; and compare different pieces of text based on their contextual similarities.&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://sanchitdilipjain.github.io/images/aws-bedrock-kb/image1.png" alt="">&lt;/p></description></item><item><title>Amazon Lightsail - Overview 🔍</title><link>https://sanchitdilipjain.github.io/post/amazon-lightsail/</link><pubDate>Sat, 11 May 2024 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-lightsail/</guid><description>&lt;h2 id="amazon-lightsail---overview">Amazon Lightsail - Overview&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>What is Amazon Lightsail?&lt;/p>
&lt;ul>
&lt;li>Amazon Lightsail is the easiest way to get started with Amazon Web Services (AWS) for anyone who needs to build websites or web applications.&lt;/li>
&lt;li>It includes everything you need to launch your project quickly—instances (virtual private servers), container services, managed databases, content delivery network (CDN) distributions, load balancers, SSD-based block storage, static IP addresses, DNS management of registered domains, and resource snapshots (backups) - for a low, predictable monthly price.&lt;/li>
&lt;li>Lightsail also offers a unique feature, Amazon Lightsail for Research. This platform opens up a world of possibilities for academics and researchers. With Lightsail for Research, you can create powerful virtual computers in the AWS Cloud, each one with pre-installed research applications, such as RStudio and Scilab. This is an exciting opportunity to accelerate your research and take it to new heights.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Why should you use Amazon Lightsail?&lt;/p></description></item><item><title>Amazon Redshift ML - Overview 🔍</title><link>https://sanchitdilipjain.github.io/post/amazon-rs-serverless-ml/</link><pubDate>Mon, 15 Apr 2024 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-rs-serverless-ml/</guid><description>&lt;h2 id="amazon-redshift-ml---overview">Amazon Redshift ML - Overview&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Amazon Redshift ML makes it easy for data analysts and database developers to create, train, and apply machine learning models using familiar SQL commands in Amazon Redshift data warehouses.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>With Redshift ML, you can take advantage of Amazon SageMaker, a fully managed machine learning service, without learning new tools or languages. Simply use SQL statements to create and train Amazon SageMaker machine learning models using your Redshift data and then use these models to make predictions.&lt;/p></description></item><item><title>How to scale Spark jobs via Karpenter with Amazon EMR on Amazon EKS?💡</title><link>https://sanchitdilipjain.github.io/post/amazon-emr-on-eks-karpenter/</link><pubDate>Mon, 01 Jan 2024 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-emr-on-eks-karpenter/</guid><description>&lt;h2 id="how-do-you-run-spark-jobs-with-amazon-emr-on-amazon-eks">How do you run Spark jobs with Amazon EMR on Amazon EKS?💡&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Amazon EMR on EKS provides a deployment option for Amazon EMR that allows you to run open-source big data frameworks on Amazon Elastic Kubernetes Service (Amazon EKS).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>With this deployment option, you can focus on running analytics workloads while Amazon EMR on EKS builds, configures, and manages containers for open-source applications.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The following diagram shows the two different deployment models for Amazon EMR.&lt;/p></description></item><item><title>How do you run Flink job with Amazon EMR on Amazon EKS?💡</title><link>https://sanchitdilipjain.github.io/post/amazon-emr-on-eks-flink/</link><pubDate>Wed, 27 Dec 2023 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-emr-on-eks-flink/</guid><description>&lt;h2 id="how-do-you-run-flink-jobs-with-amazon-emr-on-amazon-eks">How do you run Flink jobs with Amazon EMR on Amazon EKS?💡&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Amazon EMR on EKS provides a deployment option for Amazon EMR that allows you to run open-source big data frameworks on Amazon Elastic Kubernetes Service (Amazon EKS).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>With this deployment option, you can focus on running analytics workloads while Amazon EMR on EKS builds, configures, and manages containers for open-source applications.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The following diagram shows the two different deployment models for Amazon EMR.&lt;/p></description></item><item><title>How do you run Spark jobs with Amazon EMR on Amazon EKS?💡</title><link>https://sanchitdilipjain.github.io/post/amazon-emr-on-eks-spark/</link><pubDate>Tue, 26 Dec 2023 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-emr-on-eks-spark/</guid><description>&lt;h2 id="how-do-you-run-spark-jobs-with-amazon-emr-on-amazon-eks">How do you run Spark jobs with Amazon EMR on Amazon EKS?💡&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Amazon EMR on EKS provides a deployment option for Amazon EMR that allows you to run open-source big data frameworks on Amazon Elastic Kubernetes Service (Amazon EKS).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>With this deployment option, you can focus on running analytics workloads while Amazon EMR on EKS builds, configures, and manages containers for open-source applications.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The following diagram shows the two different deployment models for Amazon EMR.&lt;/p></description></item><item><title>Monitoring and Security of Amazon Redshift DataShares 💡</title><link>https://sanchitdilipjain.github.io/post/amazon-redshift-data-sharing-part4/</link><pubDate>Sat, 20 May 2023 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-redshift-data-sharing-part4/</guid><description>&lt;h2 id="monitoring-and-security-of-amazon-redshift-datashares">Monitoring and Security of Amazon Redshift DataShares&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>What is Amazon Redshift Data Sharing?&lt;/p>
&lt;ul>
&lt;li>Amazon Redshift Data Sharing is a feature that enables Redshift cluster owners to share live data across different Amazon Redshift clusters, accounts, and regions.&lt;/li>
&lt;li>With data sharing, users can easily and securely share data with other Redshift users, without having to copy or move the data.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>What are Amazon Redshift Data Sharing Benefits?&lt;/p>
&lt;ul>
&lt;li>Data sharing is a great way to improve your security and performance, as well as save money.
&lt;ul>
&lt;li>&lt;strong>Enhanced Security&lt;/strong> - By using Amazon Redshift data sharing, you can ensure that only authorized users have access to sensitive data by limiting the number of tables they can access. This helps prevent accidental or malicious disclosure of confidential information during queries and analysis.&lt;/li>
&lt;li>&lt;strong>Improved Performance&lt;/strong> - Data sharing improves query performance by allowing multiple users with different privileges to access the same table simultaneously without affecting one another&amp;rsquo;s results or causing errors in the query plan generated by SQL queries run against it (for example, if two people were trying to run a join on two distinct tables).&lt;/li>
&lt;li>&lt;strong>Cost savings&lt;/strong> - Sharing data across accounts and regions can help to reduce data storage costs and eliminate the need to move data.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Query to track all changes to the datashares: We can use the &lt;strong>svl_datashare_change_log&lt;/strong> view for tracking changes to datashares on both producer and consumer redshift clusters.&lt;/p></description></item><item><title>Permissions Management for Amazon Redshift DataShares 💡</title><link>https://sanchitdilipjain.github.io/post/amazon-redshift-data-sharing-part3/</link><pubDate>Sat, 20 May 2023 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-redshift-data-sharing-part3/</guid><description>&lt;h2 id="permissions-management-for-amazon-redshift-datashares">Permissions Management for Amazon Redshift DataShares&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>What is Amazon Redshift Data Sharing?&lt;/p>
&lt;ul>
&lt;li>Amazon Redshift Data Sharing is a feature that enables Redshift cluster owners to share live data across different Amazon Redshift clusters, accounts, and regions.&lt;/li>
&lt;li>With data sharing, users can easily and securely share data with other Redshift users, without having to copy or move the data.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>What are Amazon Redshift Data Sharing Benefits?&lt;/p>
&lt;ul>
&lt;li>Data sharing is a great way to improve your security and performance, as well as save money.
&lt;ul>
&lt;li>&lt;strong>Enhanced Security&lt;/strong> - By using Amazon Redshift data sharing, you can ensure that only authorized users have access to sensitive data by limiting the number of tables they can access. This helps prevent accidental or malicious disclosure of confidential information during queries and analysis.&lt;/li>
&lt;li>&lt;strong>Improved Performance&lt;/strong> - Data sharing improves query performance by allowing multiple users with different privileges to access the same table simultaneously without affecting one another&amp;rsquo;s results or causing errors in the query plan generated by SQL queries run against it (for example, if two people were trying to run a join on two distinct tables).&lt;/li>
&lt;li>&lt;strong>Cost savings&lt;/strong> - Sharing data across accounts and regions can help to reduce data storage costs and eliminate the need to move data.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Adding/Removing individual objects from DataShares&lt;/p></description></item><item><title>Perform Workload Isolation using Amazon Redshift Data Sharing 💡</title><link>https://sanchitdilipjain.github.io/post/amazon-redshift-data-sharing-part2/</link><pubDate>Fri, 19 May 2023 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-redshift-data-sharing-part2/</guid><description>&lt;h2 id="perform-workload-isolation-using-amazon-redshift-data-sharing">Perform Workload Isolation using Amazon Redshift Data Sharing&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>What is Amazon Redshift Data Sharing?&lt;/p>
&lt;ul>
&lt;li>Amazon Redshift Data Sharing is a feature that enables Redshift cluster owners to share live data across different Amazon Redshift clusters, accounts, and regions.&lt;/li>
&lt;li>With data sharing, users can easily and securely share data with other Redshift users, without having to copy or move the data.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>What are Amazon Redshift Data Sharing Benefits?&lt;/p>
&lt;ul>
&lt;li>Data sharing is a great way to improve your security and performance, as well as save money.
&lt;ul>
&lt;li>&lt;strong>Enhanced Security&lt;/strong> - By using Amazon Redshift data sharing, you can ensure that only authorized users have access to sensitive data by limiting the number of tables they can access. This helps prevent accidental or malicious disclosure of confidential information during queries and analysis.&lt;/li>
&lt;li>&lt;strong>Improved Performance&lt;/strong> - Data sharing improves query performance by allowing multiple users with different privileges to access the same table simultaneously without affecting one another&amp;rsquo;s results or causing errors in the query plan generated by SQL queries run against it (for example, if two people were trying to run a join on two distinct tables).&lt;/li>
&lt;li>&lt;strong>Cost savings&lt;/strong> - Sharing data across accounts and regions can help to reduce data storage costs and eliminate the need to move data.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Demo&lt;/strong>&lt;/p></description></item><item><title>Seamless Data Sharing Using Amazon Redshift 🔍</title><link>https://sanchitdilipjain.github.io/post/amazon-redshift-data-sharing-part1/</link><pubDate>Sun, 02 Apr 2023 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-redshift-data-sharing-part1/</guid><description>&lt;h2 id="seamless-data-sharing-using-amazon-redshift">Seamless Data Sharing Using Amazon Redshift&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>What is Amazon Redshift?&lt;/p>
&lt;ul>
&lt;li>Amazon Redshift is a fast, fully managed, petabyte-scale cloud-based data warehouse service. It makes it simple and cost-effective to efficiently run your analytics workloads at scale.&lt;/li>
&lt;li>Amazon Redshift uses columnar storage (also known as columnstore) to store your data in columns instead of rows, which allows it to make more efficient use of storage space and compute resources than traditional row-oriented databases like MySQL or PostgreSQL.&lt;/li>
&lt;li>In addition to its performance benefits, columnar storage also enables fast queries based on specific values within each column&amp;ndash;for example: &amp;ldquo;find all customers who ordered product X between dates Y1 and Y2.&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>What is Amazon Redshift Data Sharing?&lt;/p></description></item><item><title>Orchestration Amazon EMR Serverless using MWAA⏰</title><link>https://sanchitdilipjain.github.io/post/orchestration-emr-serverless-mwaa/</link><pubDate>Sat, 28 Jan 2023 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/orchestration-emr-serverless-mwaa/</guid><description>&lt;h2 id="orchestration-amazon-emr-serverless-using-amazon-managed-workflows-for-apache-airflow-mwaa">Orchestration Amazon EMR Serverless using Amazon Managed Workflows for Apache Airflow (MWAA)&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>What is Amazon EMR?&lt;/p>
&lt;ul>
&lt;li>Amazon EMR is a cloud big data platform running large-scale distributed data processing jobs, interactive SQL queries, and machine learning (ML) applications using open-source analytics frameworks such as Apache Spark, Apache Hive, and Presto.&lt;/li>
&lt;li>Understanding clusters and nodes
&lt;ul>
&lt;li>A cluster is a collection of Amazon Elastic Compute Cloud (Amazon EC2) instances. An instance in the cluster is called a node, and each node has role within the cluster, referred to as the node type.&lt;/li>
&lt;li>The node types in Amazon EMR are as follows:
&lt;ul>
&lt;li>&lt;strong>Master node:&lt;/strong> A node that manages the cluster by running software components to coordinate data distribution and tasks among other nodes for processing.&lt;/li>
&lt;li>&lt;strong>Core node:&lt;/strong> A node with software components that run tasks and store data in your cluster’s Hadoop Distributed File System (HDFS).&lt;/li>
&lt;li>&lt;strong>Task node:&lt;/strong> A node with software components that only runs tasks and does not store data in HDFS.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>What is Amazon EMR Serverless?&lt;/p></description></item><item><title>Amazon EMR Serverless - RDS Hive MetaStore Integration ⚒️</title><link>https://sanchitdilipjain.github.io/post/amazon-emr-serverless-hive-metastore/</link><pubDate>Sat, 21 Jan 2023 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-emr-serverless-hive-metastore/</guid><description>&lt;h2 id="amazon-emr-serverless---rds-hive-metastore-integration">Amazon EMR Serverless - RDS Hive MetaStore Integration&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>What is Amazon EMR?&lt;/p>
&lt;ul>
&lt;li>Amazon EMR is a cloud big data platform running large-scale distributed data processing jobs, interactive SQL queries, and machine learning (ML) applications using open-source analytics frameworks such as Apache Spark, Apache Hive, and Presto.&lt;/li>
&lt;li>Understanding clusters and nodes
&lt;ul>
&lt;li>A cluster is a collection of Amazon Elastic Compute Cloud (Amazon EC2) instances. An instance in the cluster is called a node, and each node has role within the cluster, referred to as the node type.&lt;/li>
&lt;li>The node types in Amazon EMR are as follows:
&lt;ul>
&lt;li>&lt;strong>Master node:&lt;/strong> A node that manages the cluster by running software components to coordinate data distribution and tasks among other nodes for processing.&lt;/li>
&lt;li>&lt;strong>Core node:&lt;/strong> A node with software components that run tasks and store data in your cluster’s Hadoop Distributed File System (HDFS).&lt;/li>
&lt;li>&lt;strong>Task node:&lt;/strong> A node with software components that only runs tasks and does not store data in HDFS.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>What is Amazon EMR Serverless?&lt;/p></description></item><item><title>Amazon EMR Serverless - Glue Hive MetaStore Integration ⚒️</title><link>https://sanchitdilipjain.github.io/post/amazon-emr-serverless-glue-metastore/</link><pubDate>Tue, 10 Jan 2023 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-emr-serverless-glue-metastore/</guid><description>&lt;h2 id="amazon-emr-serverless---glue-hive-metastore-integration">Amazon EMR Serverless - Glue Hive MetaStore Integration&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>What is Amazon EMR?&lt;/p>
&lt;ul>
&lt;li>Amazon EMR is a cloud big data platform running large-scale distributed data processing jobs, interactive SQL queries, and machine learning (ML) applications using open-source analytics frameworks such as Apache Spark, Apache Hive, and Presto.&lt;/li>
&lt;li>Understanding clusters and nodes
&lt;ul>
&lt;li>A cluster is a collection of Amazon Elastic Compute Cloud (Amazon EC2) instances. An instance in the cluster is called a node, and each node has role within the cluster, referred to as the node type.&lt;/li>
&lt;li>The node types in Amazon EMR are as follows:
&lt;ul>
&lt;li>&lt;strong>Master node:&lt;/strong> A node that manages the cluster by running software components to coordinate data distribution and tasks among other nodes for processing.&lt;/li>
&lt;li>&lt;strong>Core node:&lt;/strong> A node with software components that run tasks and store data in your cluster’s Hadoop Distributed File System (HDFS).&lt;/li>
&lt;li>&lt;strong>Task node:&lt;/strong> A node with software components that only runs tasks and does not store data in HDFS.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>What is Amazon EMR Serverless?&lt;/p></description></item><item><title>Amazon EMR Serverless - Overview 🔍</title><link>https://sanchitdilipjain.github.io/post/amazon-emr-serverless/</link><pubDate>Mon, 09 Jan 2023 12:00:00 +0000</pubDate><guid>https://sanchitdilipjain.github.io/post/amazon-emr-serverless/</guid><description>&lt;h2 id="amazon-emr-serverless---overview">Amazon EMR Serverless - Overview&lt;/h2>
&lt;p>&lt;strong>Introduction&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>What is Amazon EMR?&lt;/p>
&lt;ul>
&lt;li>Amazon EMR is a cloud big data platform running large-scale distributed data processing jobs, interactive SQL queries, and machine learning (ML) applications using open-source analytics frameworks such as Apache Spark, Apache Hive, and Presto.&lt;/li>
&lt;li>Understanding clusters and nodes
&lt;ul>
&lt;li>A cluster is a collection of Amazon Elastic Compute Cloud (Amazon EC2) instances. An instance in the cluster is called a node, and each node has role within the cluster, referred to as the node type.&lt;/li>
&lt;li>The node types in Amazon EMR are as follows:
&lt;ul>
&lt;li>&lt;strong>Master node:&lt;/strong> A node that manages the cluster by running software components to coordinate data distribution and tasks among other nodes for processing.&lt;/li>
&lt;li>&lt;strong>Core node:&lt;/strong> A node with software components that run tasks and store data in your cluster’s Hadoop Distributed File System (HDFS).&lt;/li>
&lt;li>&lt;strong>Task node:&lt;/strong> A node with software components that only runs tasks and does not store data in HDFS.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>What is Amazon EMR Serverless?&lt;/p></description></item></channel></rss>